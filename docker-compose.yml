services:
    dynamicDataCollectorService:
        build: 
            context: ./FractalDynamicDataCollector
            dockerfile: DockerfileDeployNginx
        command: python /srv/flask_app/apis/http/api/endpoints.py
        image: jperdek/dynamic-data-collector
        ports:
            - "127.0.0.1:5000:5000"
        container_name: dynamicDataCollector
        volumes:
            - source-volume:/EvolutionSPLFramework
            - evolution-volume:/evolution
        env_file: .env
        environment:
            FLASK_ENV: development
        depends_on:
            - fullyAutomatedEvolutionFramework
            - volumeCopyInit
    volumeCopyInit:
        build:
            dockerfile: Dockerfile
        command: cp -R /localFiles/splsToMerge /localFiles/resources  ${PROJECT_PATH:-/EvolutionSPLFramework}
        env_file: .env
        image: jperdek/volume-copy-init
        environment:
            PROJECT_PATH: ${PROJECT_PATH:-/EvolutionSPLFramework}
            PATH_TO_EVOLUTION_DIRECTORY: ${PATH_TO_EVOLUTION_DIRECTORY:-/evolution}
        volumes:
            - dataset-products-volume:/dataset
            - source-volume:/EvolutionSPLFramework
            - evolution-volume:/evolution
    fullyAutomatedEvolutionFramework:
        build:
            context: ./EvolutionSPLFramework
            dockerfile: Dockerfile
        image: jperdek/fully-automated-evolution
        ports:
            - "127.0.0.1:5002:5002"
        container_name: fully-automated-evolution
        links:
            - astConverterAndComplexityAnalysisAPI
        extra_hosts:
            - "host.docker.internal:host-gateway"
        volumes:
            - dataset-products-volume:/dataset
            - source-volume:/EvolutionSPLFramework
            - evolution-volume:/evolution
            - tmp-volume:/temp
        env_file: .env
        environment:
            FLASK_ENV: development
            IS_LINUX: true
            SHARE_FILES_USING_DISK: ${SHARE_FILES_USING_DISK:-true}
            DOCKER_HOST: host.docker.internal
            PROJECT_PATH: ${PROJECT_PATH:-/EvolutionSPLFramework}
            PATH_TO_EVOLUTION_DIRECTORY: ${PATH_TO_EVOLUTION_DIRECTORY:-/evolution}
            CANTO_SCRIPT_RESOURCE_LOCATION: ${CANTO_SCRIPT_RESOURCE_LOCATION:-/EvolutionSPLFramework/resources/canto/canto-0.15.js}
            PATH_TO_TEMP_DIRECTORY: ${PATH_TO_TEMP_DIRECTORY:-/temp}
        networks:
            - buildernet
        depends_on:
            - astConverterAndComplexityAnalysisAPI
            - volumeCopyInit
    astConverterAndComplexityAnalysisAPI:
        image: jperdek/ast-converter-and-complexity-analysis-api
        build:
            context: ./ConverterAndComplexityAnalyzerAPI
            dockerfile: Dockerfile
        extra_hosts:
            - "host.docker.internal:host-gateway"
        ports:
            - "127.0.0.1:5001:5001"
        networks:
            - buildernet
        volumes:
            - tmp-volume:/temp
        restart: on-failure
        environment:
            PATH_TO_TEMP_DIRECTORY: ${PATH_TO_TEMP_DIRECTORY:-/temp}
    fractalKnowledgeBase: 
        build:
            context: ./SemanticBaseNeo4j/fractalKnowledgeBase
            dockerfile: Dockerfile
        image: jperdek/fractal-knowledge-base
        hostname: neo4j
        container_name: neo4j
        ports:
            - "7475:7475"
            - "7688:7688"
        volumes:
            - ./neo4j/plugins:/plugins
        env_file: .env
        environment:
            NEO4J_AUTH: ${KNOWLEDGE_BASE_USERNAME:-neo4j}/${KNOWLEDGE_BASE_PASSWORD:-featureNeo4}
            NEO4J_dbms_logs_debug_level: ${KNOWLEDGE_BASE_LOG_LEVEL:-DEBUG}
    splsToProcessMessageQueue:
        env_file: .env
        image: rabbitmq:4.0-management-alpine
        environment:
            RABBITMQ_DEFAULT_USER: ${PROCESSING_QUEUE_USERNAME:-splManager}
            RABBITMQ_DEFAULT_PASS: ${PROCESSING_QUEUE_PASSWORD:-splManager}
            RABBITMQ_DEFAULT_VHOST: ${PROCESSING_QUEUE_VHOST:-/evolution}
        ports:
            - "127.0.0.1:15672:15672"
        volumes:
            - rabbitmq-volume:/var/lib/rabbitmq/
        networks:
            - buildernet
volumes:
    source-volume:
    evolution-volume:
    dataset-products-volume:
    rabbitmq-volume:
    tmp-volume:
networks:
    buildernet:
        driver: "bridge"